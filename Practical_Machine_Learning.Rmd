---
title: "Practical Machine Learning"
author: "Julio Bolivar"
date: "10 May 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

We consider 5 activity classes, gathered from 4 subjects wearing accelerometers mounted on their waist, left thigh, right arm, and right ankle. As basic input features to our classifier we use 12 attributes derived from a time window of 150ms. Finally, the classifier uses a committee AdaBoost that combines ten Decision Trees. The observed classifier accuracy is 99.4%.

## Model Building

```{r echo=FALSE}
library("data.table")
library("caret")

pmlTrain <- fread('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
pmlTest <- fread('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')

summary(pmlTrain)

head(pmlTrain)
```

The data was collected per user and for some period of time. There are several features available. We should remove some features which are irrelevant for prediction. Some features are only relevant for aggregated values calculated for observations with new window = yes. They should be removed, since they are not present in the test set. We will try a random forest and perform cross validation by splicing our data into train and test sets.

## Cross Validation

```{r echo=FALSE}
pmlTrainFilter <- pmlTrain[pmlTrain$new_window != "yes"]
pmlTrainFilter <- subset(pmlTrainFilter, select = colSums(is.na(pmlTrainFilter)) == 0)
pmlTrainFilter <- Filter(function(x) !(all(x=="")), pmlTrainFilter)
pmlTrainFilter <- pmlTrainFilter[,-c("V1", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")]

pmlTestFilter <- pmlTest[pmlTest$new_window != "yes"]
pmlTestFilter <- subset(pmlTestFilter, select = colSums(is.na(pmlTestFilter)) == 0)
pmlTestFilter <- Filter(function(x) !(all(x=="")), pmlTestFilter)
pmlTestFilter <- pmlTestFilter[,-c("V1", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")]

inTrain <- createDataPartition(y=pmlTrainFilter$classe, p=0.7, list = FALSE)

training <- pmlTrainFilter[inTrain,]
testing <- pmlTrainFilter[-inTrain,]

modFit <- train(y=training$classe, x=training[,-c("classe")], data=training, method="rf")
```

## Expected Out of Sample Error

```{r}
modFit
```

The trained model has high accuracy (98%). We can test its generalization by using the test set.

```{r echo=FALSE}
pred <- predict(modFit, testing)
table(pred,testing$classe)
```

We can indeed confirm that the model does not make many errors. The highest error number occur for predictions of classe D, where some predictions are incorrectly classifed as C.