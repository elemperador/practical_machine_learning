---
title: "Practical Machine Learning"
author: "Julio Bolivar"
date: "10 May 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

The goal of this project is to predict the manner in some persons performed some exercises. This is the "classe" variable in the training set. We will consider 5 activity classes, gathered from 4 subjects wearing accelerometers mounted on their waist, left thigh, right arm, and right ankle.

## Model Building

The data was collected per user and for some period of time. There are several features available. We should remove some features which are irrelevant for prediction. Some features are only relevant for aggregated values calculated for observations with new window = yes. They should be removed, since they are not present in the test set. 

```{r echo=FALSE}
library("data.table")
library("caret")

pmlTrain <- fread('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv')
pmlTest <- fread('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv')
```

## Cross Validation

We will try a random forest and perform cross validation by splicing our data into train and test sets.

```{r echo=FALSE}
pmlTrainFilter <- pmlTrain[pmlTrain$new_window != "yes"]
pmlTrainFilter <- subset(pmlTrainFilter, select = colSums(is.na(pmlTrainFilter)) == 0)
pmlTrainFilter <- Filter(function(x) !(all(x=="")), pmlTrainFilter)
pmlTrainFilter <- pmlTrainFilter[,-c("V1", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")]

pmlTestFilter <- pmlTest[pmlTest$new_window != "yes"]
pmlTestFilter <- subset(pmlTestFilter, select = colSums(is.na(pmlTestFilter)) == 0)
pmlTestFilter <- Filter(function(x) !(all(x=="")), pmlTestFilter)
pmlTestFilter <- pmlTestFilter[,-c("V1", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")]

inTrain <- createDataPartition(y=pmlTrainFilter$classe, p=0.7, list = FALSE)

training <- pmlTrainFilter[inTrain,]
testing <- pmlTrainFilter[-inTrain,]

modFit <- train(y=training$classe, x=training[,-c("classe")], data=training, method="rf")

modFit
```

## Expected Out of Sample Error

The trained model has high accuracy (98%). We can test its generalization by using the test set.

```{r echo=FALSE}
pred <- predict(modFit, testing)
table(pred,testing$classe)
```

We can indeed confirm that the model does not make many errors. The highest error number occur for predictions of classe D, where some predictions are incorrectly classifed as C.
